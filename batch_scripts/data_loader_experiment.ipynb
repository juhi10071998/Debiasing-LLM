{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900b8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "class BiasDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, n_tokens):\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "        data = pd.read_csv(data_path)\n",
    "        \n",
    "        data = data.head(20)\n",
    "        self.x = data.to_numpy()\n",
    "        self.n_samples = len(data)\n",
    "        self.n_tokens = n_tokens\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token        \n",
    "        ## return a bunch of sentences here, at any instance the dataloader gets called only once,         \n",
    "        sentence1, sentence2 = self.x[index][0], self.x[index][1]   \n",
    "        return sentence1, sentence2\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        #separate the sentences for the two identity groups so that in a batch can send to the model.\n",
    "        #returns for this, to get a tensor of lists from the list of tensors.\n",
    "\n",
    "        batch_1, batch_2 = [ele[0] for ele in batch], [ele[1] for ele in batch]\n",
    "        \n",
    "        tokenized_1 = self.tokenizer.batch_encode_plus(batch_1, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids_1 = tokenized_1[\"input_ids\"]\n",
    "        attention_masks_1 = tokenized_1[\"attention_mask\"]       \n",
    "        input_ids_1 = torch.stack([torch.cat([torch.full((1, self.n_tokens), 50256)[0], input_id], 0) for input_id in input_ids_1])\n",
    "        attention_masks_1 = torch.stack([torch.cat([torch.full((1, self.n_tokens), 1)[0], attention_mask], 0) for attention_mask in attention_masks_1])         \n",
    "                \n",
    "        tokenized_2 = self.tokenizer.batch_encode_plus(batch_2, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids_2 = tokenized_2[\"input_ids\"]\n",
    "        attention_masks_2 = tokenized_2[\"attention_mask\"]        \n",
    "        input_ids_2 = torch.stack([torch.cat([torch.full((1, self.n_tokens), 50256)[0], input_id], 0) for input_id in input_ids_2])\n",
    "        attention_masks_2 = torch.stack([torch.cat([torch.full((1, self.n_tokens), 1)[0], attention_mask], 0) for attention_mask in attention_masks_2])\n",
    "        \n",
    "        return (input_ids_1, attention_masks_1, batch_1), (input_ids_2, attention_masks_2, batch_2)\n",
    "    \n",
    "    def get_dataloader(self, batch_size):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=self.collate_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eea009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('gentleman had a reputation for', 'lady had a reputation for'),\n",
       " ('gentleman was famous for', 'lady was famous for'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = BiasDataset(\"../data/occupation.csv\", n_tokens = 5)\n",
    "\n",
    "dataset[0], dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7364a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataset.get_dataloader(batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154474de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gentleman part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   550,   257,\n",
      "          8507,   329, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373,  5863,\n",
      "           329, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  1026,   373,  2219,  3725,   326,\n",
      "         22427, 43748,  3353,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373,  8018,\n",
      "           329, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  8061,  3917, 22427,   351, 50256,\n",
      "         50256, 50256, 50256, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]), ['gentleman had a reputation for', 'gentleman was famous for', 'It was common knowledge that gentleman excelled in', 'gentleman was recognized for', 'People associated gentleman with'])\n",
      "**************\n",
      "\n",
      "lady part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,    75,  4597,   550,   257,  8507,\n",
      "           329, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373,  5863,   329,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  1026,   373,  2219,  3725,   326,\n",
      "         10846, 43748,  3353,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373,  8018,   329,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  8061,  3917, 10846,   351, 50256,\n",
      "         50256, 50256, 50256, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]), ['lady had a reputation for', 'lady was famous for', 'It was common knowledge that lady excelled in', 'lady was recognized for', 'People associated lady with'])\n",
      "**************\n",
      "\n",
      "**************\n",
      "\n",
      "gentleman part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   550,   257,\n",
      "          2610,  1700,   286],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373, 10810,\n",
      "           329, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   550,   257,\n",
      "          7310, 46283,   329],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373, 22140,\n",
      "           329, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,   464,  1438,   286, 22427,   373,\n",
      "         33271,   351, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]), ['gentleman had a track record of', 'gentleman was acknowledged for', 'gentleman had a distinct notoriety for', 'gentleman was renowned for', 'The name of gentleman was synonymous with'])\n",
      "**************\n",
      "\n",
      "lady part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,    75,  4597,   550,   257,  2610,\n",
      "          1700,   286],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373, 10810,   329,\n",
      "         50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   550,   257,  7310,\n",
      "         46283,   329],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373, 22140,   329,\n",
      "         50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,   464,  1438,   286, 10846,   373,\n",
      "         33271,   351]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), ['lady had a track record of', 'lady was acknowledged for', 'lady had a distinct notoriety for', 'lady was renowned for', 'The name of lady was synonymous with'])\n",
      "**************\n",
      "\n",
      "**************\n",
      "\n",
      "gentleman part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   550,   257,\n",
      "           880,    12, 27718,  8507,   329],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373, 13943,\n",
      "           329, 50256, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  1026,   373,  6768,  6292,   326,\n",
      "         22427,   373, 14297,   287, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   550,   257,\n",
      "          9208,  5055,   329, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373, 18876,\n",
      "           329, 50256, 50256, 50256, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), ['gentleman had a well-established reputation for', 'gentleman was celebrated for', 'It was widely accepted that gentleman was skilled in', 'gentleman had a prominent standing for', 'gentleman was distinguished for'])\n",
      "**************\n",
      "\n",
      "lady part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,    75,  4597,   550,   257,   880,\n",
      "            12, 27718,  8507,   329],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373, 13943,   329,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  1026,   373,  6768,  6292,   326,\n",
      "         10846,   373, 14297,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   550,   257,  9208,\n",
      "          5055,   329, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373, 18876,   329,\n",
      "         50256, 50256, 50256, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), ['lady had a well-established reputation for', 'lady was celebrated for', 'It was widely accepted that lady was skilled in', 'lady had a prominent standing for', 'lady was distinguished for'])\n",
      "**************\n",
      "\n",
      "**************\n",
      "\n",
      "gentleman part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373,  2968,\n",
      "           306,  1900,   329, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  1026,   373,  6768,  8018,   326,\n",
      "         22427,   373, 39318,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   373, 14462,\n",
      "           329, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,   464, 13572,   286, 22427,   373,\n",
      "           880,    12,  4002,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,  6783,   293,   805,   550,   257,\n",
      "         12411, 10655,   329, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]), ['gentleman was popularly known for', 'It was widely recognized that gentleman was proficient in', 'gentleman was respected for', 'The expertise of gentleman was well-known in', 'gentleman had a notable legacy for'])\n",
      "**************\n",
      "\n",
      "lady part is : \n",
      "(tensor([[50256, 50256, 50256, 50256, 50256,    75,  4597,   373,  2968,   306,\n",
      "          1900,   329, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,  1026,   373,  6768,  8018,   326,\n",
      "         10846,   373, 39318,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   373, 14462,   329,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [50256, 50256, 50256, 50256, 50256,   464, 13572,   286, 10846,   373,\n",
      "           880,    12,  4002,   287],\n",
      "        [50256, 50256, 50256, 50256, 50256,    75,  4597,   550,   257, 12411,\n",
      "         10655,   329, 50256, 50256]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]), ['lady was popularly known for', 'It was widely recognized that lady was proficient in', 'lady was respected for', 'The expertise of lady was well-known in', 'lady had a notable legacy for'])\n",
      "**************\n",
      "\n",
      "**************\n",
      "\n",
      "tensor([[[ -43.4316,  -39.8363,  -43.0659,  ...,  -54.0876,  -54.3451,\n",
      "           -42.3644],\n",
      "         [ -98.5535,  -91.0628,  -93.8414,  ..., -112.6983, -113.3016,\n",
      "          -100.2930],\n",
      "         [ -97.6956,  -90.2930,  -92.9740,  ..., -111.9370, -112.6350,\n",
      "           -99.7249],\n",
      "         ...,\n",
      "         [  37.0038,   37.3172,   31.6104,  ...,   28.4243,   28.4940,\n",
      "            35.2380],\n",
      "         [ -65.7742,  -65.1110,  -69.1673,  ...,  -70.5974,  -70.1860,\n",
      "           -67.0121],\n",
      "         [ -87.5118,  -79.9613,  -82.7055,  ..., -100.7903, -101.2958,\n",
      "           -88.7173]],\n",
      "\n",
      "        [[ -43.4316,  -39.8363,  -43.0659,  ...,  -54.0876,  -54.3451,\n",
      "           -42.3644],\n",
      "         [ -98.5535,  -91.0628,  -93.8414,  ..., -112.6983, -113.3016,\n",
      "          -100.2930],\n",
      "         [ -97.6956,  -90.2930,  -92.9740,  ..., -111.9370, -112.6350,\n",
      "           -99.7249],\n",
      "         ...,\n",
      "         [ -87.5745,  -86.5021,  -89.4190,  ...,  -93.6378,  -90.6784,\n",
      "           -89.6695],\n",
      "         [  45.5711,   43.4519,   38.9770,  ...,   36.9538,   36.9071,\n",
      "            42.9388],\n",
      "         [ -93.1169,  -90.8565,  -95.7079,  ...,  -94.9006,  -95.6574,\n",
      "           -93.5681]],\n",
      "\n",
      "        [[ -43.4316,  -39.8363,  -43.0659,  ...,  -54.0876,  -54.3451,\n",
      "           -42.3644],\n",
      "         [ -98.5535,  -91.0628,  -93.8414,  ..., -112.6983, -113.3016,\n",
      "          -100.2930],\n",
      "         [ -97.6956,  -90.2930,  -92.9740,  ..., -111.9370, -112.6350,\n",
      "           -99.7249],\n",
      "         ...,\n",
      "         [ -89.9219,  -82.7562,  -85.3757,  ..., -102.6740, -103.0218,\n",
      "           -91.0504],\n",
      "         [ -90.0140,  -82.8430,  -85.4630,  ..., -102.7856, -103.1317,\n",
      "           -91.1497],\n",
      "         [ -90.1017,  -82.9271,  -85.5473,  ..., -102.8940, -103.2333,\n",
      "           -91.2421]],\n",
      "\n",
      "        [[ -43.4316,  -39.8363,  -43.0659,  ...,  -54.0876,  -54.3451,\n",
      "           -42.3644],\n",
      "         [ -98.5535,  -91.0628,  -93.8414,  ..., -112.6983, -113.3016,\n",
      "          -100.2930],\n",
      "         [ -97.6956,  -90.2930,  -92.9740,  ..., -111.9370, -112.6350,\n",
      "           -99.7249],\n",
      "         ...,\n",
      "         [-101.3822,  -99.2179, -102.6769,  ..., -108.1347, -106.7994,\n",
      "          -102.4322],\n",
      "         [ -96.8754,  -98.8809, -105.3152,  ..., -105.5952, -107.3706,\n",
      "          -100.4168],\n",
      "         [ -79.5905,  -77.9153,  -83.2005,  ...,  -81.1494,  -84.2769,\n",
      "           -80.9721]],\n",
      "\n",
      "        [[ -43.4316,  -39.8363,  -43.0659,  ...,  -54.0876,  -54.3451,\n",
      "           -42.3644],\n",
      "         [ -98.5535,  -91.0628,  -93.8414,  ..., -112.6983, -113.3016,\n",
      "          -100.2930],\n",
      "         [ -97.6956,  -90.2930,  -92.9740,  ..., -111.9370, -112.6350,\n",
      "           -99.7249],\n",
      "         ...,\n",
      "         [-108.4855, -111.6985, -115.8208,  ..., -119.8754, -120.2613,\n",
      "          -111.3702],\n",
      "         [ -90.1817,  -90.1945,  -94.2256,  ...,  -92.5267,  -95.8081,\n",
      "           -91.6751],\n",
      "         [ -93.3752,  -86.1489,  -88.8799,  ..., -106.4417, -106.8431,\n",
      "           -94.0679]]], grad_fn=<UnsafeViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    print(\"gentleman part is : \")\n",
    "    print(data[0])\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    logits = model(input_ids=data[0][0], attention_mask=data[0][1])[0]\n",
    "\n",
    "    print(\"**************\\n\")\n",
    "    print(\"lady part is : \")\n",
    "    print(data[1])\n",
    "    print(\"**************\\n\")\n",
    "    print(\"**************\\n\")\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969ee6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd22af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
